---
---

@string{aps = {American Physical Society,}}

@InProceedings{10.1007/978-3-031-73477-9_16,
author="Agarwal, Vedik
and Chandnani, Chirag Jitendra
and Kulkarni, Shlok Chetan
and Aren, Aditya
and Srinivasan, Kathiravan",
editor="K, Hemachandran
and Rodriguez, Raul Villamarin
and Rege, Manjeet
and Ade-Ibijola, Abejide
and Ong, Kok-Leong
and Piuri, Vincenzo",
title="A Comparative Analysis of Aggregation Methods in Federated Learning on MNIST",
booktitle="Artificial Intelligence and Knowledge Processing",
year="2025",
publisher="Springer Nature Switzerland",
address="Cham",
pages="225--238",
abstract="Machine learning methods that protect privacy are now highly sought after in the big data and ubiquitous connection era. Federated Learning (FL) is a unique and revolutionary method that solves this problem by allowing machine learning models to be trained on several dispersed clients or devices without requiring the transfer of raw data between the devices and servers. Since then, it has emerged as a prospective paradigm for training various machine learning models while preserving data privacy. This paper offers a thorough analysis of different Federated Learning aggregation procedures and how they affect the accuracy and loss of the model. Within the Federated Learning framework, this paper explores and contrasts four different aggregating methods: Federated Averaging (FedAvg), Federated Proximal (FedProx), Federated Median (FedMedian) and q-FedAvg. We assess these strategies using the Modified National Institute of Standards and Technology (MNIST) dataset, a benchmark dataset for handwritten digit classification, using a Convolutional Neural Network (CNN) based model. Our test results show notable differences in model performance between various aggregation techniques. The paper unveils distinct convergence behaviors and stability characteristics of each algorithm under various data distribution scenarios. Notably, FedProx emerges as a promising choice, demonstrating consistent performance across diverse data distributions. The paper's findings underscore the importance of careful algorithm selection based on specific application requirements and data characteristics.",
isbn="978-3-031-73477-9"
}

@ARTICLE{10857281,
  author={Jitendra Chandnani, Chirag and Agarwal, Vedik and Chetan Kulkarni, Shlok and Aren, Aditya and Amali, D. Geraldine Bessie and Srinivasan, Kathiravan},
  journal={IEEE Access}, 
  title={A Physics-Based Hyper Parameter Optimized Federated Multi-Layered Deep Learning Model for Intrusion Detection in IoT Networks}, 
  year={2025},
  volume={13},
  number={},
  pages={21992-22010},
  keywords={Internet of Things;Data models;Training;Accuracy;Optimization;Data privacy;Adaptation models;Servers;Federated learning;Feature extraction;Hyperparameter optimization;federated learning;deep learning;intrusion detection systems},
  doi={10.1109/ACCESS.2025.3535952}}
